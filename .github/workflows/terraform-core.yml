name: "[Setup] Initialise and perform Terraform actions"
on:
  workflow_call:
    inputs:
      environment_name:
        required: false
        default: dev
        type: string
      aws_region:
        required: false
        default: eu-west-2
        type: string
      destructive_action_check:
        required: false
        type: boolean
        default: false
      execute_terraform_plan:
        required: false
        type: boolean
        default: false
        description: "Whether or not to apply the Terraform code. Set to false for a plan only."
      terraform_action:
        required: false
        type: string
        default: "apply"
        description: "Which Terraform action to run. 'apply' or 'destroy'"
      stack_config:
        description: "A detailed matrix containing the Terraform stack configuration and dependencies"
        required: true
        type: string
      max_parallel:
        required: false
        description: "The maximum number of jobs to run at the same time. This should normally be 1 to avoid race conditions."
        type: number
        default: 1
      repo:
        required: false
        type: string
        default: ${{ github.repository }}
        description: "Specify the org/repo of the repo containing Terraform code. Normally left blank to clone calling repo."
      ref:
        required: false
        type: string
        default: ${{ github.ref }}
        description: "Specify the branch of the Terraform code. Normally left blank to use calling ref."
      upload_plan:
        required: false
        type: boolean
        default: false
        description: "Create an artifact containing the resulting Terraform plan. Incompatible with download_existing_plan"
      download_existing_plan:
        required: false
        type: boolean
        default: false
        description: "Download an artifact containing an existing Terraform plan created by a previous run. Incompatible with upload_plan"
      python_version:
        required: false
        type: string
        default: "3.12"
        description: "The version of python required when building packages via Terraform"
      artefact_path:
        required: false
        type: string
        default: "nonexistentfile.txt"
        description: "If there are artefacts created from data sources, specify the path from the TF stack dir here so they are uploaded before applying"
    
    secrets:
      AWS_ROLE_NAME:
        required: false
        description: "The name of the role to assume when Terraform interacts with the AWS API."
      AWS_ACCOUNT_ID:
        required: false
        description: "The AWS account ID where Terraform will create resources. This account must contain the role specified in AWS_ROLE_NAME."
      AWS_ACCESS_KEY_ID:
        required: false
        description: "AWS credentials used by Terraform to interact with AWS API. Not required if using OIDC."
      AWS_SECRET_ACCESS_KEY:
        required: false
        description: "AWS credentials used by Terraform to interact with AWS API. Not required if using OIDC."
      AZURE_SUBSCRIPTION_ID:
        required: false
      AZURE_TENANT_ID:
        required: false
      AZURE_CLIENT_ID:
        required: false
      AZURE_RESOURCE_GROUP_NAME:
        required: false
      GH_TOKEN:
        required: false
        description: "Github Token used by Terraform to create and manage resources in Github"
      TF_MODULES_SSH_DEPLOY_KEY:
        required: false
        description: "The SSH key used to clone Terraform modules downloaded as part of the Terraform init"
      REPO_SSH_DEPLOY_KEY:
        required: false
        description: "The SSH key used to checkout private remote repos"
      SSH_DEPLOY_KEY:
        required: false
        description: "Deprecated: Use either TF_MODULES_SSH_DEPLOY_KEY or REPO_SSH_DEPLOY_KEY instead."
      TF_PLAN_ENCRYPTION_PASSPHRASE:
        required: true
        description: "The passphrase used to encrypt Terraform Plans before uploading them as Github Artifacts"

jobs:
  initialise:
    name: "Initialise and run Terraform for ${{ matrix.stack.directory }}"
    runs-on: "${{ matrix.stack.runner_label }}"
    environment: ${{ inputs.environment_name }}
    defaults:
      run:
        shell: bash
    strategy:
      matrix:
        stack: "${{ fromJSON(inputs.stack_config) }}"
      max-parallel: ${{ inputs.max_parallel }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.repo }}
          ref: ${{ inputs.ref }}
          ssh-key: ${{ secrets.REPO_SSH_DEPLOY_KEY }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version }}

      - name: Export variables
        run: | 
          echo "state_name=$(basename ${{ matrix.stack.directory }})" >> $GITHUB_ENV

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        env:
          AWS_ACCESS_KEY_ID: "${{ secrets.AWS_ACCESS_KEY_ID }}"
          AWS_SECRET_ACCESS_KEY: "${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          AWS_ACCOUNT_ID: "${{ secrets.AWS_ACCOUNT_ID }}"
          AWS_ROLE_NAME: "${{ secrets.AWS_ROLE_NAME }}"
        if: ${{ env.AWS_ROLE_NAME != '' && env.AWS_ACCOUNT_ID != '' }}
        with:
          aws-region: "${{ inputs.aws_region }}"
          role-to-assume: "arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/${{ env.AWS_ROLE_NAME }}"
          aws-access-key-id: "${{ env.AWS_ACCESS_KEY_ID }}"
          aws-secret-access-key: "${{ env.AWS_SECRET_ACCESS_KEY }}"

      - name: Configure Azure Credentials
        uses: azure/login@v2
        env:
          AZURE_CLIENT_ID: "${{ secrets.AZURE_CLIENT_ID }}"
          AZURE_TENANT_ID: "${{ secrets.AZURE_TENANT_ID }}"
          AZURE_SUBSCRIPTION_ID: "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
        if: >-
          ${{ env.AZURE_CLIENT_ID != '' && env.AZURE_TENANT_ID != '' &&
          env.AZURE_SUBSCRIPTION_ID != '' }}
        with:
          client-id: "${{ env.AZURE_CLIENT_ID }}"
          tenant-id: "${{ env.AZURE_TENANT_ID }}"
          subscription-id: "${{ env.AZURE_SUBSCRIPTION_ID }}"

      - name: Copy required files from root directory
        env:
          DIRECTORY: "${{ matrix.stack.directory }}"
        run: |
          files_to_copy=("providers.tf" "terraform.tf")

          for FILE in "${files_to_copy[@]}"; do
            if [[ ! -f "$DIRECTORY"/"$FILE" ]]; then
                echo "NOTE - $(basename "$DIRECTORY") will attempt to use the "$FILE" file in the root directory"
                cp "$FILE" "$DIRECTORY"/ || exit 1
            else
              echo "NOTE - $(basename "$DIRECTORY") has its own "$FILE" file. Not copying "$FILE" from root"
            fi
          done

      - name: Decide which Terraform version to use based on constraints
        uses: ukhsa-collaboration/devops-github-actions/.github/actions/parse-terraform-version@v0.9.0
        id: terraform_version
        with:
          tf_file: "${{ matrix.stack.directory }}/terraform.tf"

      - name: Setup Terraform for self-hosted runner
        if: ${{ contains(matrix.stack.runner_label, 'self-hosted') }}
        run: |
          echo "Terraform Version: ${{ steps.terraform_version.outputs.tf_version }}" 
          tfenv use ${{ steps.terraform_version.outputs.tf_version }}
          terraform --version
        working-directory: ${{ matrix.stack.directory }}

      - name: Setup Terraform for GHE runner
        if: ${{ !contains(matrix.stack.runner_label, 'self-hosted') }}
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "${{ steps.terraform_version.outputs.tf_version }}"
          terraform_wrapper: false

      - name: Determine Backend Type
        working-directory: "${{ matrix.stack.directory }}"
        id: backend
        run: |
          backend_type=$(grep -oP 'backend\s+"?\K[^"\s]+' ./backend.tf)
          echo "backend_type=$backend_type" >> $GITHUB_OUTPUT

      - name: Add SSH deploy key to ssh-agent
        env:
          SSH_DEPLOY_KEY: ${{ secrets.TF_MODULES_SSH_DEPLOY_KEY != '' && secrets.TF_MODULES_SSH_DEPLOY_KEY || secrets.SSH_DEPLOY_KEY }}
          SSH_AUTH_SOCK: "/tmp/ssh_agent.sock"
        run: |
          # Add SSH deploy key to ssh-agent to allow internal or private ukhsa-collaboration
          # modules to be downloaded during terraform init.
          if [ -n "$SSH_DEPLOY_KEY" ]; then
            mkdir -p ~/.ssh
            ssh-keyscan github.com >> ~/.ssh/known_hosts
            eval $(ssh-agent -a $SSH_AUTH_SOCK -s)
            echo "$SSH_DEPLOY_KEY" | tr -d '\r' | ssh-add -
          fi
          
          echo "SSH_AUTH_SOCK=$SSH_AUTH_SOCK" >> $GITHUB_ENV

      - name: Configure Terraform plugin cache
        run: |
          echo "TF_PLUGIN_CACHE_DIR=$HOME/.terraform.d/plugin-cache" >>"$GITHUB_ENV"
          mkdir --parents "$HOME/.terraform.d/plugin-cache"

      - name: Cache Terraform providers
        uses: actions/cache@v4
        with:
          path: |
            ~/.terraform.d/plugin-cache
          key: terraform-${{ runner.os }}-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            terraform-${{ runner.os }}-
  
      - name: Terraform Init with AWS S3 Backend
        working-directory: "${{ matrix.stack.directory }}"
        if: ${{ steps.backend.outputs.backend_type == 's3' }}
        env:
          AWS_ACCOUNT_ID: "${{ secrets.AWS_ACCOUNT_ID }}"
          AWS_REGION: "${{ inputs.aws_region }}"
          ENVIRONMENT_NAME: "${{ inputs.environment_name }}"
          DIRECTORY: "${{ matrix.stack.directory }}"
          TF_VERSION: "${{ steps.terraform_version.outputs.tf_version }}"
        run: |
          s3_key="${ENVIRONMENT_NAME}"/"$state_name"/terraform.tfstate
          s3_bucket=${AWS_ACCOUNT_ID}-${AWS_REGION}-state
          # `dynamodb_table` is deprecated by Terraform from verison 1.11.0 . Use the new use_lockfile
          # flag if the Terraform version supports it.
          # TODO: Remove this conditional in future. 
          if [ "$(printf '%s\n' "1.11.0" "$TF_VERSION" | sort -V | head -n1)" = "1.11.0" ]; then
            terraform init \
            -backend-config=use_lockfile=true \
            -backend-config=bucket="${s3_bucket}" \
            -backend-config=key="${s3_key}"
          else
            dynamodb_table=${AWS_REGION}-state-locks
            terraform init \
              -backend-config=dynamodb_table="${dynamodb_table}" \
              -backend-config=bucket="${s3_bucket}" \
              -backend-config=key="${s3_key}"
          fi

      - name: Terraform Init with Azure Backend
        if: ${{ steps.backend.outputs.backend_type == 'azurerm' }}
        working-directory: "${{ matrix.stack.directory }}"
        env:
          ENVIRONMENT_NAME: "${{ inputs.environment_name }}"
          DIRECTORY: "${{ matrix.stack.directory }}"
          ARM_USE_OIDC: true
          ARM_CLIENT_ID: "${{ secrets.AZURE_CLIENT_ID }}"
          ARM_SUBSCRIPTION_ID: "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
          ARM_TENANT_ID: "${{ secrets.AZURE_TENANT_ID }}"
        run: |
          # Container name needs to be a valid DNS name with less than 63 characters.
          container_name=$(dirname "$DIRECTORY" | tr -cd '[:alnum:]-' | cut -c1-62)
          storage_account_name=$(echo "${{ secrets.AZURE_SUBSCRIPTION_ID }}" | tr -d '-' | cut -c 1-12)state
          terraform init \
            -backend-config=storage_account_name="${storage_account_name}" \
            -backend-config=container_name="$container_name" \
            -backend-config=key=$ENVIRONMENT_NAME/"$state_name"/terraform.tfstate \
            -backend-config=resource_group_name="${{ secrets.AZURE_RESOURCE_GROUP_NAME }}"

      - name: Check if the state file is empty
        working-directory: "${{ matrix.stack.directory }}"
        id: state_empty
        shell: bash
        env:
          execute_terraform_plan: ${{ inputs.execute_terraform_plan }}
          ARM_USE_OIDC: true
          ARM_CLIENT_ID: "${{ secrets.AZURE_CLIENT_ID }}"
          ARM_SUBSCRIPTION_ID: "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
          ARM_TENANT_ID: "${{ secrets.AZURE_TENANT_ID }}"
        run: |
          set -euo pipefail

          skip_workflow=false
      
          # Capture Terraform state list output; suppress errors if state doesn't exist.
          output=$(terraform state list 2>/dev/null || true)
          echo "DEBUG: terraform state list output: '$output'"
      
          # Check if output is empty and if we are not executing a terraform plan.
          if [ -z "$output" ] && [ "${execute_terraform_plan}" = "false" ]; then
            echo "DEBUG: No state found and execute_terraform_plan is false. Skipping further steps."
            skip_workflow=true
          else
            echo "DEBUG: Either state exists or terraform plan is set to execute."
          fi
      
          echo "skip_workflow=$skip_workflow" >> $GITHUB_OUTPUT
      

      - name: Find Terraform variables
        id: variables
        shell: bash
        env:
          DIRECTORY: "${{ matrix.stack.directory }}"
          ENVIRONMENT_NAME: "${{ inputs.environment_name }}"
        run: |
          find_app_var_files() {
            local dir=$1
            local tfvars=$(find ./$dir/tfvars/ -name "*${ENVIRONMENT_NAME}.tfvars" -print -quit)
            local json=$(find ./$dir/tfvars/ -name "*${ENVIRONMENT_NAME}.tfvars.json" -print -quit)
            
            if [[ -f "$tfvars" ]]; then
              echo "-var-file=$(readlink -f $tfvars)"
            elif [[ -f "$json" ]]; then
              echo "-var-file=$(readlink -f $json)"
            fi
          }

          find_env_var_files() {
            local tfvars="./environment/${ENVIRONMENT_NAME}.tfvars"
            local json="./environment/${ENVIRONMENT_NAME}.tfvars.json"
            if [[ -f "$tfvars" ]]; then
              echo "-var-file=$(readlink -f $tfvars)"
            elif [[ -f "$json" ]]; then
              echo "-var-file=$(readlink -f $json)"
            fi
          }

          find_global_var_file() {
            local tfvars="globals.tfvars"
            local json="globals.tfvars.json"
            if [[ -f "$tfvars" ]]; then
              echo "-var-file=$(readlink -f $tfvars)"
            elif [[ -f "$json" ]]; then
              echo "-var-file=$(readlink -f $json)"
            fi
          }

          global_vars_file=$(find_global_var_file)
          app_var_file=$(find_app_var_files "$DIRECTORY")
          env_var_file=$(find_env_var_files)
          full_variable_flags="$global_vars_file $app_var_file $env_var_file"

          echo "tf_vars=$full_variable_flags" >> $GITHUB_OUTPUT

      - uses: actions/download-artifact@v4
        id: download_plan
        if: ( inputs.download_existing_plan == true && steps.state_empty.outputs.skip_workflow == 'false' )
        with:
          name: "${{ env.state_name }}-${{ inputs.environment_name }}-artefacts"
          path: ${{ matrix.stack.directory }}

      - name: Decrypt Terraform plan
        if: steps.download_plan.conclusion == 'success'
        working-directory: "${{ matrix.stack.directory }}"
        env:
          ENCRYPTION_PASSPHRASE: ${{ secrets.TF_PLAN_ENCRYPTION_PASSPHRASE }}
        run: |
          pass_file=$(mktemp)
          printf "%s" "$ENCRYPTION_PASSPHRASE" > "$pass_file"
          gpg --decrypt --batch --passphrase-file "$pass_file" --out tfplan tfplan.gpg

      - name: Terraform Plan
        id: tf_plan
        working-directory: "${{ matrix.stack.directory }}"
        continue-on-error: true
        if: steps.download_plan.conclusion == 'skipped' && steps.state_empty.outputs.skip_workflow == 'false' 
        shell: bash
        env:
          ENVIRONMENT_NAME: "${{ inputs.environment_name }}"
          TERRAFORM_VARIABLES: "${{ steps.variables.outputs.tf_vars }}"
          ARM_USE_OIDC: true
          ARM_CLIENT_ID: "${{ secrets.AZURE_CLIENT_ID }}"
          ARM_SUBSCRIPTION_ID: "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
          ARM_TENANT_ID: "${{ secrets.AZURE_TENANT_ID }}"
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          TERRAFORM_ACTION: ${{ inputs.terraform_action }}
          SKIP_DESTROY: "${{ matrix.stack.skip_when_destroying }}"
        run: |
          set -euo pipefail

          terraform_exit_code=0
          # Determine whether to plan a destroy or a regular plan.
          if [[ "$TERRAFORM_ACTION" == "destroy" ]]; then
            if [[ "$SKIP_DESTROY" == "false" ]]; then
              echo "DEBUG: Running terraform plan for destroy"
              terraform plan -lock-timeout=5m -destroy -no-color -input=false -out=tfplan -detailed-exitcode -compact-warnings ${TERRAFORM_VARIABLES} || terraform_exit_code=$?
            else
              echo "DEBUG: Skipping terraform plan because SKIP_DESTROY flag in this stack is true"
              echo "terraform_exit_code=0" >> $GITHUB_OUTPUT
              echo "planned_changes=false" >> $GITHUB_OUTPUT
              exit 0
            fi
          else
            echo "DEBUG: Running standard terraform plan"
            terraform plan -lock-timeout=5m -no-color -input=false -out=tfplan -detailed-exitcode -compact-warnings ${TERRAFORM_VARIABLES} || terraform_exit_code=$?
          fi

          echo "DEBUG: Terraform exit code is $terraform_exit_code"
          echo "terraform_exit_code=$terraform_exit_code" >> $GITHUB_OUTPUT

          terraform show -json tfplan | jq > tfplan.json
          
          if [ $terraform_exit_code -eq 0 ]; then
            echo "DEBUG: Terraform Plan exit code indicated no changes."
            planned_changes=false
          elif [ $terraform_exit_code -eq 2 ]; then
            echo "DEBUG: Terraform Plan exit code indicated changes."
            planned_changes=true
          else
            echo "ERROR: Terraform plan failed with exit code $terraform_exit_code" >&2
            exit $terraform_exit_code
          fi

          echo "planned_changes=$planned_changes" >> $GITHUB_OUTPUT

      - name: Update stack matrix
        working-directory: "${{ matrix.stack.directory }}"
        run: |
          # If the tf_plan step was skipped because of no state, persist the stack configuration with planned_changes.
          if [ "${{ steps.tf_plan.conclusion }}" == "skipped" ]; then
            planned_changes="${{ matrix.stack.planned_changes }}"
          else
            planned_changes="${{ steps.tf_plan.outputs.planned_changes }}"
          fi

          echo "runner_label is: ${{ matrix.stack.runner_label }}"

          jq -n \
            --arg dir "${{ matrix.stack.directory }}" \
            --argjson runner_label '${{ toJSON(matrix.stack.runner_label) }}' \
            --argjson planned_changes "$planned_changes" \
            --argjson order "${{ matrix.stack.order }}" \
            --argjson skip_when_destroying "${{ matrix.stack.skip_when_destroying }}" \
            '{
              directory: $dir,
              runner_label: ($runner_label | if type=="array" then . else [.] end),
              planned_changes: $planned_changes,
              order: $order,
              skip_when_destroying: $skip_when_destroying
            }' \
            > updated_matrix.json

          cat updated_matrix.json

      - name: Encrypt Terraform plan
        id: encrypt_plan
        env:
          ENCRYPTION_PASSPHRASE: ${{ secrets.TF_PLAN_ENCRYPTION_PASSPHRASE }}
        working-directory: "${{ matrix.stack.directory }}"
        if: ${{ inputs.upload_plan && steps.tf_plan.conclusion != 'skipped' }}
        run: |
          pass_file=$(mktemp)
          printf "%s" "$ENCRYPTION_PASSPHRASE" > "$pass_file"
          gpg --batch --symmetric --passphrase-file "$pass_file" tfplan
          gpg --batch --symmetric --passphrase-file "$pass_file" tfplan.json

          # Delete unencrypted plan files to prevent accidental upload.
          rm tfplan tfplan.json

      - name: Upload Terraform Plan and matrix
        uses: actions/upload-artifact@v4
        if: ${{ inputs.upload_plan }}
        with:
          name: "${{ env.state_name }}-${{ inputs.environment_name }}-artefacts"
          path: |
            ${{ matrix.stack.directory }}/tfplan.gpg
            ${{ matrix.stack.directory }}/tfplan.json.gpg
            ${{ matrix.stack.directory }}/updated_matrix.json
            ${{ matrix.stack.directory }}/${{ inputs.artefact_path }}
          if-no-files-found: warn
          compression-level: 1
          retention-days: 1
  
      - name: Terraform Apply
        if: >-
          ${{ inputs.execute_terraform_plan &&
          steps.state_empty.outputs.skip_workflow == 'false' &&
          (inputs.terraform_action != 'destroy' || matrix.stack.skip_when_destroying == false)}}
        working-directory: "${{ matrix.stack.directory }}"
        env:
          ENVIRONMENT_NAME: "${{ inputs.environment_name }}"
          TERRAFORM_VARIABLES: "${{ steps.variables.outputs.tf_vars }}"
          ARM_USE_OIDC: true
          ARM_CLIENT_ID: "${{ secrets.AZURE_CLIENT_ID }}"
          ARM_SUBSCRIPTION_ID: "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
          ARM_TENANT_ID: "${{ secrets.AZURE_TENANT_ID }}"
          GH_TOKEN: "${{ secrets.GH_TOKEN }}"
        run: terraform apply -lock-timeout=5m -no-color -input=false tfplan